{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# T3.3 Estimación del error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Índice\n",
    "\n",
    "1. Error teórico de un clasificador\n",
    "2. Error del clasificador de Bayes\n",
    "3. Estimación del error de un clasificador"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Error teórico de un clasificador\n",
    "\n",
    "**Propósito:** $\\;$ determinar la probabilidad de error de un clasificador dado, $\\,c(\\boldsymbol{x})=\\operatorname{argmax}_c g_c(\\boldsymbol{x})$ \n",
    "\n",
    "**Error a posteriori:** $\\;$ probabilidad de error para a un $\\,\\boldsymbol{x}\\,$ dado; 1 menos la probabilidad de acertar:\n",
    "$$\\varepsilon(c(\\boldsymbol{x}))=1-P(c(\\boldsymbol{x})\\mid\\boldsymbol{x})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Error (a priori) con $\\mathcal{X}$ discreto:** $\\;$ probabilidad de error esperada de acuerdo con la **probabilidad incondicional** de $\\,\\boldsymbol{x}$:\n",
    "$$\\varepsilon=\\mathbb{E}_{\\boldsymbol{x}}[\\varepsilon(c(\\boldsymbol{x}))]%\n",
    "=\\sum_{\\boldsymbol{x}}P(\\boldsymbol{x})\\,\\varepsilon(c(\\boldsymbol{x}))$$\n",
    "\n",
    "**Ejemplo:** $\\;\\mathcal{X}=\\{0,1\\}^2,\\,C=2$\n",
    "\n",
    "<div><table border-collapse: collapse><tr>\n",
    "<td style=\"border: none; vertical-align:top; padding:0; margin:0; text-align:center;\" width=500><center>\n",
    "\n",
    "<p style=\"text-align:center;\"><em>Conocimiento teórico</em></p>\n",
    "\n",
    "|$x_1$|$x_2$|$P(\\boldsymbol{x})$|$P(1\\vert\\boldsymbol{x})$|$P(2\\vert\\boldsymbol{x})$|\n",
    "|:-:|:-:|:-:|:-:|:-:|\n",
    "|$0$|$0$|$1/2$|$1$|$0$|\n",
    "|$0$|$1$|$1/4$|$3/4$|$1/4$|\n",
    "|$1$|$0$|$1/4$|$1/4$|$3/4$|\n",
    "|$1$|$1$|$0$|$0$|$1$|\n",
    "\n",
    "</center></td>\n",
    "<td style=\"border: none; vertical-align:top; padding:0; margin:0; text-align:center;\" width=500><center>\n",
    "\n",
    "<p style=\"text-align:center;\"><em>Error teórico de un clasificador dado</em></p>\n",
    "\n",
    "|$x_1$|$x_2$|$c(\\boldsymbol{x})$|$\\varepsilon(c(\\boldsymbol{x}))$|$P(\\boldsymbol{x})\\varepsilon(c(\\boldsymbol{x}))$|\n",
    "|:-:|:-:|:-:|:-:|:-:|\n",
    "|$0$|$0$|$1$|$0$|$0$|\n",
    "|$0$|$1$|$1$|$1/4$|$1/16$|\n",
    "|$1$|$0$|$1$|$3/4$|$3/16$|\n",
    "|$1$|$1$|$2$|$0$|$0$|\n",
    "\n",
    "$$\\varepsilon=1/16+3/16=1/4$$\n",
    "\n",
    "</center></td></tr></table></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Error (a priori) con $\\mathcal{X}$ continuo:** $\\;$ probabilidad de error esperada de acuerdo con la **densidad de probabilidad incondicional** de $\\,\\boldsymbol{x}$:\n",
    "$$\\varepsilon=\\mathbb{E}_{\\boldsymbol{x}}[\\varepsilon(c(\\boldsymbol{x}))]%\n",
    "=\\int P(\\boldsymbol{x})\\,\\varepsilon(c(\\boldsymbol{x}))\\,d\\boldsymbol{x}$$\n",
    "\n",
    "**Ejemplo:** $\\quad\\mathcal{X}=\\mathbb{R}\\quad C=2\\quad c(x)=1$\n",
    "\n",
    "*Conocimiento teórico:* $\\quad P(x)=\\begin{cases}1/2&x\\in[-3/4,-1/4]\\\\1&x\\in[-1/4,1/4]\\\\1/2&x\\in[1/4, 3/4]\\end{cases}\\qquad P(c=1\\vert x)=\\begin{cases}1&x\\in[-3/4,-1/4]\\\\1/2&x\\in[-1/4,1/4]\\\\0&x\\in[1/4, 3/4]\\end{cases}$\n",
    "\n",
    "*Error teórico de un clasificador dado:*\n",
    "$$\\varepsilon(c(x))=\\begin{cases}0&x\\in[-3/4,-1/4]\\\\1/2&x\\in[-1/4,1/4]\\\\1&x\\in[1/4, 3/4]\\end{cases}\n",
    "\\;\\to\\;\\varepsilon=\\int P(x)\\,\\varepsilon(c(x))\\,dx=\\int_{-1/4}^{1/4}1\\cdot\\frac{1}{2}\\,dx+\\int_{1/4}^{3/4}\\frac{1}{2}\\cdot 1\\,dx=\\frac{1}{2}$$\n",
    "\n",
    "Nota: $\\int_{a}^{b}f(x)\\,dx=[G(x)]_a^b = G(b) - G(a)\\,$ por la regla de Barrow, donde $G(x)$ es la primitiva de $f(x)$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Error del clasificador de Bayes\n",
    "\n",
    "**Clasificador de Bayes o regla de decisión MAP (máxima a posteriori):** $\\quad c^*(\\boldsymbol{x})=\\operatorname*{argmax}_c\\; P(c\\mid\\boldsymbol{x})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Error de Bayes a posteriori:** $\\quad\\varepsilon(c^*(\\boldsymbol{x}))=1-P(c^*(\\boldsymbol{x})\\mid\\boldsymbol{x})=1-\\max_c P(c\\mid\\boldsymbol{x})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Error de Bayes (a priori) con $\\mathcal{X}$ discreto:** $\\quad\\varepsilon^*=\\mathbb{E}_{\\boldsymbol{x}}[\\varepsilon(c^*(\\boldsymbol{x}))]=\\sum_{\\boldsymbol{x}}P(\\boldsymbol{x})\\,\\varepsilon(c^*(\\boldsymbol{x}))$\n",
    "\n",
    "**Ejemplo (cont.):** $\\;\\mathcal{X}=\\{0,1\\}^2,\\,C=2$\n",
    "\n",
    "<div><table border-collapse: collapse><tr>\n",
    "<td style=\"border: none; vertical-align:top; padding:0; margin:0; text-align:center;\" width=500><center>\n",
    "\n",
    "<p style=\"text-align:center;\"><em>Conocimiento teórico</em></p>\n",
    "\n",
    "|$x_1$|$x_2$|$P(\\boldsymbol{x})$|$P(1\\vert\\boldsymbol{x})$|$P(2\\vert\\boldsymbol{x})$|\n",
    "|:-:|:-:|:-:|:-:|:-:|\n",
    "|$0$|$0$|$1/2$|$1$|$0$|\n",
    "|$0$|$1$|$1/4$|$3/4$|$1/4$|\n",
    "|$1$|$0$|$1/4$|$1/4$|$3/4$|\n",
    "|$1$|$1$|$0$|$0$|$1$|\n",
    "\n",
    "</center></td>\n",
    "<td style=\"border: none; vertical-align:top; padding:0; margin:0; text-align:center;\" width=500><center>\n",
    "\n",
    "<p style=\"text-align:center;\"><em>Error de Bayes</em></p>\n",
    "\n",
    "|$x_1$|$x_2$|$c^*(\\boldsymbol{x})$|$\\varepsilon(c^*(\\boldsymbol{x}))$|$P(\\boldsymbol{x})\\varepsilon(c^*(\\boldsymbol{x}))$|\n",
    "|:-:|:-:|:-:|:-:|:-:|\n",
    "|$0$|$0$|$1$|$0$|$0$|\n",
    "|$0$|$1$|$1$|$1/4$|$1/16$|\n",
    "|$1$|$0$|$2$|$1/4$|$1/16$|\n",
    "|$1$|$1$|$2$|$0$|$0$|\n",
    "\n",
    "$$\\varepsilon^*=1/16+1/16=1/8$$\n",
    "\n",
    "</center></td></tr></table></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Error de Bayes (a priori) con $\\mathcal{X}$ continuo:** $\\quad\\varepsilon^*=\\mathbb{E}_{\\boldsymbol{x}}[\\varepsilon(c^*(\\boldsymbol{x}))]=\\int p(\\boldsymbol{x})\\,\\varepsilon(c^*(\\boldsymbol{x}))\\,d\\boldsymbol{x}$\n",
    "\n",
    "**Ejemplo (cont.):** $\\quad\\mathcal{X}=\\mathbb{R}\\quad C=2\\quad c^*(x)=1+\\mathbb{I}(1/4\\leq x\\leq 3/4)$\n",
    "\n",
    "*Conocimiento teórico:* $\\quad p(x)=\\begin{cases}1/2&x\\in[-3/4,-1/4]\\\\1&x\\in[-1/4,1/4]\\\\1/2&x\\in[1/4, 3/4]\\end{cases}\\qquad P(c=1\\mid x)=\\begin{cases}1&x\\in[-3/4,-1/4]\\\\1/2&x\\in[-1/4,1/4]\\\\0&x\\in[1/4, 3/4]\\end{cases}$\n",
    "\n",
    "*Error de Bayes:* $\\displaystyle\\quad\\varepsilon(c^*(x))=\\begin{cases}0&x\\in[-3/4,-1/4]\\\\1/2&x\\in[-1/4,1/4]\\\\0&x\\in[1/4, 3/4]\\end{cases}\\;\\to\\;\\varepsilon^*=\\int p(x)\\,\\varepsilon(c^*(x))\\,dx=\\int_{-1/4}^{1/4}1\\cdot\\frac{1}{2}\\,dx=\\frac{1}{4}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Estimación del error de un clasificador\n",
    "\n",
    "**Imposibilidad de calcular el error teórico exacto:** $\\;$ ya que no tenemos el conocimiento teórico exacto.\n",
    "\n",
    "**Estimación del error por resustitución:** $\\;$ consiste en calcular la tasa de error con los datos de entrenamiento.\n",
    "\n",
    "**Resustitución es optimista:** $\\;$ un clasificador que se limite a classificar bien los datos de entrenamiento (por ejemplo\n",
    "mediante memorización) obtendrá una estimación del error (casi) nula, pero funcionará mal con datos futuros, no vistos en entrenamiento.\n",
    "\n",
    "**Estimación del error por holdout:** $\\;$ consiste en \"dejar fuera\" del entrenamiento una parte de los datos disponibles, el cual se denominará **conjunto de test**, y calcular la tasa de error con dichos datos de test.\n",
    "\n",
    "**Holdout es (ligeramente) pesimista:** $\\;$ ya que estima el error de un clasificador entrenado con menos datos de los disponibles y, en general, la tasa de error empeora al reducir la cantidad de datos de entrenamiento.\n",
    "\n",
    "**Aproximación normal a la distribución del estimador holdout:** $\\;$ si la cantidad de datos de test, $M$, es grande, el estimador holdout puede considerarse una variable aleatoria normal cuya media es el error estimado $\\hat{\\varepsilon}$ y cuya variancia es inversamente proporcional a $M$:\n",
    "$$\\varepsilon \\sim\\mathcal{N}\\left(\\hat{\\varepsilon}, \\frac{\\hat{\\varepsilon}(1-\\hat{\\varepsilon})}{M}\\right)$$\n",
    "\n",
    "**Intervalo de confianza al 95\\%:** $\\;$ la aproximación normal permite acompañar la estimación del error con un intervalo de confianza al 95\\%:\n",
    "$$I_{95\\%}=[\\hat{\\varepsilon}-\\hat{r},\\hat{\\varepsilon}+\\hat{r}]%\n",
    "\\quad\\text{con radio}\\quad%\n",
    "\\hat{r}=1.96\\sqrt{\\frac{\\hat{\\varepsilon}(1-\\hat{\\varepsilon})}{M}}$$\n",
    "\n",
    "**Ejemplo:** $\\;$ si obtenemos $100$ errores al clasificar $M=2000$ muestras de test:\n",
    "$$\\begin{align*}\n",
    "\\hat{\\varepsilon}&=\\frac{100}{2000}=0.05=5\\%\\\\\n",
    "\\hat{r}&=1.96\\sqrt{\\frac{0.05\\cdot 0.95}{2000}}=0.01\\\\\n",
    "I_{95\\%}&=[0.04, 0.06]=[4\\%, 6\\%]\n",
    "\\end{align*}$$\n",
    "\n",
    "Es decir, si bien la tasa de error **estimada** $\\hat{\\varepsilon}$ es del $5\\%$, la tasa de error **real** $\\varepsilon$ estará, con una confianza (probabilidad) del $95\\%$, dentro el intervalo $[4\\%, 6\\%]$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejemplo (cont.):** y si obtenemos $10$ errores al clasificar $M=200$ muestras de test?\n",
    "\n",
    "$$\\begin{align*}\n",
    "\\hat{\\varepsilon}&=\\frac{10}{200}=0.05=5\\%\\\\\n",
    "\\hat{r}&=1.96\\sqrt{\\frac{0.05\\cdot 0.95}{200}}=0.03\\\\\n",
    "I_{95\\%}&=[0.02, 0.08]=[2\\%, 8\\%]\n",
    "\\end{align*}$$\n",
    "\n",
    "En este caso, la tasa de error estimada $\\hat{\\varepsilon}$ es la misma que en el caso anterior. Ahora bien, como disponemos de menos muestras de evaluación, la varianza es mayor, por lo que el intervalo de confianza al 95% es más amplio. Esto nos indica que la tasa de error estimada $\\hat{\\varepsilon}$ es menos precisa."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
