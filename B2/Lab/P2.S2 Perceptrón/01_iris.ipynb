{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perceptrón aplicado al corpus y tarea Iris"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Lectura del corpus\n",
    "\n",
    "Cargamos el corpus Iris y comprobamos que las matrices de datos `X` y etiquetas `y` contienen el número de filas y columnas que esperamos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape = (150, 4)\n",
      "y.shape = (150, 1)\n",
      "\n",
      "[Xy]: stacked X and y matrices column-wise (150 rows, 4+1 cols)\n",
      "\n",
      "# Fist 5 rows: \n",
      "\n",
      "[[5.1015625  3.5        1.40039062 0.19995117 0.        ]\n",
      " [4.8984375  3.         1.40039062 0.19995117 0.        ]\n",
      " [4.69921875 3.19921875 1.29980469 0.19995117 0.        ]\n",
      " [4.6015625  3.09960938 1.5        0.19995117 0.        ]\n",
      " [5.         3.59960938 1.40039062 0.19995117 0.        ]]\n",
      "\n",
      " ...\n",
      "\n",
      "# Last 5 rows:\n",
      "\n",
      "[[6.69921875 3.         5.19921875 2.30078125 2.        ]\n",
      " [6.30078125 2.5        5.         1.90039062 2.        ]\n",
      " [6.5        3.         5.19921875 2.         2.        ]\n",
      " [6.19921875 3.40039062 5.3984375  2.30078125 2.        ]\n",
      " [5.8984375  3.         5.1015625  1.79980469 2.        ]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np;\n",
    "from sklearn.datasets import load_iris;\n",
    "iris = load_iris(); \n",
    "X = iris.data.astype(np.float16);\n",
    "y = iris.target.astype(np.uint).reshape(-1, 1); \n",
    "print(\"X.shape =\", X.shape);\n",
    "print(\"y.shape =\", y.shape);\n",
    "print(\"\\n[Xy]: stacked X and y matrices column-wise (%d rows, %d+%d cols)\\n\" % \n",
    "        (X.shape[0], X.shape[1], y.shape[1]));\n",
    "print(\"# Fist 5 rows: \\n\"); \n",
    "print(np.hstack([X, y])[:5, :]);\n",
    "print(\"\\n ...\\n\");\n",
    "print(\"# Last 5 rows:\\n\");\n",
    "print(np.hstack([X, y])[-5:, :]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Partición del corpus \n",
    "\n",
    "Creamos un split del dataset iris con un $20\\%$ de datos (30 muestras) para evaluación (*test*), y el resto (120 muestras) para entrenamiento (*training*), barajando previamente los datos de acuerdo con una semilla dada para la generación de números aleatorios. \n",
    "\n",
    "Aquí, como en todo código que incluya aleatoriedad (que requiera generar números aleatorios), conviene fijar dicha semilla para poder reproducir experimentos posteriormente con exactitud. En este caso, usaremos como semilla un objeto `int` con valor 23."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape = (120, 4) ; X_test.shape = (30, 4)\n",
      "y_train.shape = (120, 1) ; y_test.shape = (30, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "       train_test_split(X, y, \n",
    "                        test_size=0.2, \n",
    "                        shuffle=True, \n",
    "                        random_state=23)\n",
    "print(\"X_train.shape =\", X_train.shape, \"; X_test.shape =\", X_test.shape)\n",
    "print(\"y_train.shape =\", y_train.shape, \"; y_test.shape =\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Implementación del algoritmo Perceptrón\n",
    "\n",
    "Implementación del algoritmo de aprendizaje Perceptrón, partiendo de pesos nulos. \n",
    "\n",
    "Recibe como parámetros de entrada:\n",
    "\n",
    "- Matriz de muestras de entrenamiento `X`, de tamaño $N\\times D$,\n",
    "- Matriz (vector columna) de etiquetas de clase `y`, de tamaño $N\\times 1$,\n",
    "- Valores de los hiperparámetros del algoritmo (a optimizar de manera experimental):\n",
    "    - Variable de margen `b` $\\ge 0$,\n",
    "    - Factor de aprendizaje `a` $> 0$,\n",
    "    - Número máximo de iteraciones `K` $> 0$. \n",
    "\n",
    "Devuelve:\n",
    "\n",
    "- Matriz de pesos optimizados `W`, en notación homogénea, de tamaño $(1+D)\\times C$,  \n",
    "- Número de muestras de train incorrectamente clasificadas `E` durante la última iteración realizada,\n",
    "- Número de iteraciones ejecutadas `k`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perceptron(X, y, b=0.1, a=1.0, K=200):\n",
    "    N, D = X.shape;                               # N: num. muestras; D: dimensionalidad\n",
    "    Y = np.unique(y);                             # Y: Conjunto etiquetas de clase\n",
    "    C = Y.size;                                   # C: número de clases\n",
    "    W = np.zeros((1+D, C));                       # Inicialización matriz de pesos nulos\n",
    "    for k in range(1, K+1):\n",
    "        E = 0                                     # E: Contador de errores de clasificación\n",
    "        for n in range(N):\n",
    "            xn = np.array([1, *X[n, :]]);         # xn: vector x en notación compacta\n",
    "            yn = np.squeeze(np.where(Y==y[n]));   # yn: etiq. de clase correcta en {0,...,C-1}\n",
    "            gn = W[:,yn] @ xn;                    # gn: valor f.discr. de la clase correcta\n",
    "            err = False;\n",
    "            for c in np.arange(C):\n",
    "                if c != yn:\n",
    "                    if W[:,c] @ xn + b >= gn:     # ¿Se clasifica mal la muestra xn?\n",
    "                        W[:, c] = W[:, c] - a*xn; # Ajustamos pesos de la clase incorrecta\n",
    "                        err = True;\n",
    "            if err:\n",
    "                W[:, yn] = W[:, yn] + a*xn;       # Ajustamos pesos de la clase correcta\n",
    "                E = E + 1;\n",
    "        if E == 0:                                # Algoritmo converge, finalizamos entrenamiento.\n",
    "            break;  \n",
    "    return W, E, k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nota 1:** el carácter `*` delante de una secuencia actúa como [operador de desempaquetado (unpacking operator)]((https://peps.python.org/pep-0448/)).\n",
    "\n",
    "**Nota 2:** el [operador `@`](https://peps.python.org/pep-0465/) denota multiplicación de matrices.\n",
    "\n",
    "Conviene resaltar que **el valor `E` devuelto no nos sirve para calcular la tasa de error de train**, ya que los pesos se modifican a lo largo de la iteración. La tasa de error en train se debe calcular con unos pesos fijos (invariables) para todas las muestras, p.e. al finalizar el entrenamiento, o incluso al final de cada iteración. `E` solo nos sirve para conocer el número de actualizaciones de pesos realizadas en la última iteración del algoritmo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Aprendizaje de un clasificador lineal con Perceptrón\n",
    "\n",
    "Perceptrón devuelve una matriz de pesos optimizados $\\mathbf{W}^*$ que minimiza el número de errores de entrenamiento (con margen `b`):\n",
    "\n",
    "$$\\mathbf{W}^*=\\operatorname*{argmin}_{\\mathbf{W}=(\\boldsymbol{w}_1,\\dotsc,\\boldsymbol{w}_C)}\\sum_n\\;\\mathbb{I}\\biggl(\\max_{c\\neq y_n}\\;(\\boldsymbol{w}_c^t\\boldsymbol{x}_n+b) \\;>\\; \\boldsymbol{w}_{y_n}^t\\boldsymbol{x}_n\\biggr)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de iteraciones ejecutadas:  100\n",
      "Número de errores de entrenamiento durante la última iteración:  11\n",
      "Vectores de pesos de las clases (por columnas, notación homogénea):\n",
      " [[   7.           49.         -103.        ]\n",
      " [ -54.73046875  -56.33984375 -183.015625  ]\n",
      " [  38.47070312  -18.66210938 -152.42578125]\n",
      " [-178.015625   -100.046875     69.14257812]\n",
      " [ -78.10290527 -101.27648926  113.07946777]]\n"
     ]
    }
   ],
   "source": [
    "W, E, k = perceptron(X_train, y_train, K=100);\n",
    "print(\"Número de iteraciones ejecutadas: \", k);\n",
    "print(\"Número de errores de entrenamiento durante la última iteración: \", E);\n",
    "print(\"Vectores de pesos de las clases (por columnas, notación homogénea):\\n\", W);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Cálculo de tasas de error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tasa de error en train:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de error en train: 17.5%\n"
     ]
    }
   ],
   "source": [
    "# Matriz de muestras de train en notación homogénea:\n",
    "X_train_h = np.hstack([np.ones((len(X_train), 1)), X_train]);\n",
    "# Clasificamos muestras de test, obtenemos etiquetas:\n",
    "y_train_pred  = np.argmax(X_train_h @ W, axis=1).reshape(-1, 1); \n",
    "# Calculamos tasa error en train:\n",
    "err_train = np.count_nonzero(y_train_pred != y_train) / len(X_train);  \n",
    "print(f\"Tasa de error en train: {err_train:.1%}\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tasa de error en test:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de error en test: 26.7%\n"
     ]
    }
   ],
   "source": [
    "X_test_h = np.hstack([np.ones((len(X_test), 1)), X_test]);\n",
    "y_test_pred  = np.argmax(X_test_h @ W, axis=1).reshape(-1, 1);\n",
    "err_test = np.count_nonzero(y_test_pred != y_test) / len(X_test);  \n",
    "print(f\"Tasa de error en test: {err_test:.1%}\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretación de resultados:** $\\;$ los datos de entrenamiento no parecen linealmente separables (el algoritmo no converge). Con margen $b=0.1$ se obtiene un error de clasificación en train de $17.5%$ y en test del $26.7\\%$. Esto indica que el clasificador evaluado no generaliza bien (funciona significativamente peor con muestras no vistas en entrenamiento). Cabe matizar que se dispone de muy pocas muestras de test (30), por lo que los resultados pueden ser poco representativos o fiables. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Optimización de hiperparámetros\n",
    "\n",
    "**Ajuste del margen:** $\\;$ experimento para optimizar el valor del hiperparámetro $b$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#       b\t E\t   k\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0.00\t 9\t 100\n",
      "     0.01\t 9\t 100\n",
      "     0.10\t11\t 100\n",
      "    10.00\t 8\t 100\n",
      "   100.00\t17\t 100\n",
      "  1000.00\t45\t 100\n"
     ]
    }
   ],
   "source": [
    "print(\"# {:>7s}\\t{:>2s}\\t{:>4s}\".format(\"b\", \"E\", \"k\"));\n",
    "for b in (.0, .01, .1, 10, 100, 1000):\n",
    "    W, E, k = perceptron(X_train, y_train, b=b, K=100)\n",
    "    print(\"  {:7.2f}\\t{:>2d}\\t{:>4d}\".format(b, E, k));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Viendo esta tabla, con el número de errores en entrenamiento acaecidos durante la última iteración, no podemos extraer conclusiones. Deberíamos evaluar la tasa de error en test (y quizás también en train) para determinar el valor de `b` óptimo (que permite generalizar mejor).\n",
    "\n",
    "Como regla general, **seleccionaremos el conjunto de valores de hiperparámetros que minimicen la tasa de error en test**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Ejercicios\n",
    "\n",
    "1. Modifica la celda de código anterior para que calcule las tasas de error en train y test para cada experimento y las muestre en la tabla de resultados, añadiendo sendas columnas adicionales. \n",
    "2. A partir de la información proporcionada por las tasas de error en train y test, determina cuál es el valor de `b` óptimo. Puedes ampliar la exploración con otros valores de `b`, para tratar de optimizar aún más la tasa de error.\n",
    "3. Explora también diferentes valores para los hiperparámetros `a` y `K`. En esta tarea tan pequeña y sencilla no tienen un gran impacto, pero su exploración en otras tareas puede proporcionar mejoras adicionales, especialmente con `K` cuando el algoritmo no converge (¿cuándo es mejor parar el entrenamiento?).  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sin-2324",
   "language": "python",
   "name": "sin-2324"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
